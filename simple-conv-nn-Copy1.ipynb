{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import autograd\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the images and labels\n",
    "images = np.load(\"./images.npy\").copy().astype(np.float32)\n",
    "labels = np.load(\"./labels.npy\").copy().astype(np.int) # 0:apple 1:baseball 2:cookie 3:clock 4:fan\n",
    "\n",
    "# prepare some constants\n",
    "NUM_IMAGES, HEIGHT, WIDTH = images.shape\n",
    "NUM_CLASSES = len(np.unique(labels))\n",
    "NUM_OPT_STEPS = 5000 # default, may change in different experiments\n",
    "NUM_HIDDEN = 100\n",
    "\n",
    "# transform each image to a [height*width, 1] column vector\n",
    "X = images.reshape(NUM_IMAGES, HEIGHT * WIDTH) \n",
    "Y = labels\n",
    "\n",
    "# mean normalization on image data (mean = 0.0 and var = 1.0)\n",
    "mean = X.mean()\n",
    "s = X.std()\n",
    "X = (X - mean) / s\n",
    "\n",
    "# separate training, cross-validation and testing data (40000:5000:5000), all FloatTensors\n",
    "train_X, cross_X, test_X = X[:40000], X[40000:45000], X[45000:] \n",
    "train_Y, cross_Y, test_Y = Y[:40000], Y[40000:45000], Y[45000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TwoLayerNN(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Customized 2-layer NN, subclassing the nn.Module\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = torch.nn.Linear(HEIGHT * WIDTH, NUM_HIDDEN)\n",
    "        self.linear2 = torch.nn.Linear(NUM_HIDDEN, NUM_CLASSES)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        y_hat = self.linear2(x)\n",
    "        return y_hat\n",
    "    \n",
    "model = TwoLayerNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(batch_size):\n",
    "    \"\"\"\n",
    "    Taking a single optimization step using batch size randomly-chosen examples\n",
    "    Args: \n",
    "        batch_size: int \n",
    "    Returns:\n",
    "        A int, the loss of training for 1 time using [batch_size] examples from training data\n",
    "    \"\"\"    \n",
    "    # model.train() puts our model in train mode, which can require different\n",
    "    # behavior than eval mode (for example in the case of dropout).\n",
    "    model.train()\n",
    "    # i is is a 1-D array with shape [batch_size]\n",
    "    i = np.random.choice(train_X.shape[0], size=batch_size, replace=False)\n",
    "    x = autograd.Variable(torch.from_numpy(train_X[i]))\n",
    "    y = autograd.Variable(torch.from_numpy(train_Y[i]))\n",
    "    optimizer.zero_grad()\n",
    "    y_hat_ = model(x)\n",
    "    loss = F.cross_entropy(y_hat_, y) #.cross_entropy(input, target, weight=None, size_average=True,\n",
    "                                      #               ignore_index=-100, reduce=True)\n",
    "                                      # input – Variable (N,C) where C = number of classes\n",
    "                                      # target – Variable (N) where each value is 0 <= targets[i] <= C-1\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(y, y_hat):\n",
    "    \"\"\"Compute training accuracy.\n",
    "    Args:\n",
    "       y: A 1-D int NumPy array.\n",
    "       y_hat: A 1-D int NumPy array.\n",
    "    Returns:\n",
    "       A float, the fraction of time y[i] == y_hat[i].\n",
    "    \"\"\"\n",
    "    return torch.mean((y == y_hat).float())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def approx_train_accuracy():\n",
    "    \"\"\"\n",
    "    Compute accuracy on random training data\n",
    "    \"\"\"\n",
    "    # for a single batch of size 1000 to compute training accuracy\n",
    "    random_size = 1000\n",
    "    # test mode\n",
    "    model.eval() \n",
    "    # i is is a 1-D array with shape [batch_size]\n",
    "    i = np.random.choice(train_X.shape[0], size=random_size, replace=False)\n",
    "    x = autograd.Variable(torch.from_numpy(train_X[i])) \n",
    "    y = autograd.Variable(torch.from_numpy(train_Y[i]))\n",
    "    y_hat = model(x) # (1000, NUM_CLASSES)\n",
    "    y_hat = y_hat.max(dim = 1)[1] # get max on each row, and get the index of that max element\n",
    "    accu = accuracy(y.data, y_hat.data)\n",
    "    return accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def val_accuracy():\n",
    "    \"\"\"\n",
    "    Computes validation accuracy using a \n",
    "    single batch and all validation examples.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    x = autograd.Variable(torch.from_numpy(cross_X))\n",
    "    y = autograd.Variable(torch.from_numpy(cross_Y))\n",
    "    y_hat = model(x)\n",
    "    y_hat = y_hat.max(dim = 1)[1]\n",
    "    accu = accuracy(y.data, y_hat.data)\n",
    "    return accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotResult(train_accs, val_accs):\n",
    "    \"\"\"\n",
    "    Plot training accuracy and validation \n",
    "    accuracy as a function of optimization step.\n",
    "    Args:\n",
    "        train_accs: float list, training accurasy\n",
    "        val_accs: float list, validation accurasy\n",
    "    \"\"\"\n",
    "    plt.plot(train_accs, 'r-')\n",
    "    plt.plot(val_accs, 'b-')\n",
    "    plt.title(\"training(red) accuracy vs validation(blue) accuracy - step\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_predict(batch_size=1, num_steps=NUM_OPT_STEPS, \n",
    "                      opt=torch.optim.SGD, learning_rate=1e-3,\n",
    "                      show_loss=True, show_curve=True):\n",
    "    \"\"\"\n",
    "    Train the model \n",
    "    Args:\n",
    "        batch_size: batch_size of traiing data in each training step, default=1;\n",
    "        num_steps: number of training times, defult=5000;\n",
    "        opt: optimizer, default is SGD;\n",
    "        lr: learning rate, default=0.001;\n",
    "        show_loss: if print the loss during training;\n",
    "        show_curve: if plot the training/validation accuracy curve at the end;\n",
    "    \"\"\"\n",
    "    optimizer = opt(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    train_accs, val_accs = [], [] # clear the previous results\n",
    "    for i in range(num_steps):\n",
    "        train(batch_size)\n",
    "        if i % 100 == 0:\n",
    "            train_accs.append(approx_train_accuracy())\n",
    "            val_accs.append(val_accuracy())\n",
    "            if show_loss:\n",
    "                print(\"%6d %5.2f %5.2f\" % (i, train_accs[-1], val_accs[-1]))\n",
    "    if show_curve:\n",
    "        plotResult(train_accs, val_accs)\n",
    "    return train_accs, val_accs\n",
    "    \n",
    "# Train this network for 5,000 steps using a batch size of 1, \n",
    "# using Adam as the optimizer with a learning rate of 0.001.\n",
    "_, _ = train_and_predict(batch_size=1, num_steps=5000, opt=torch.optim.Adam, \n",
    "                  learning_rate=0.001, show_loss=True, show_curve=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: Above we mentioned that convolutional filters are applied to local image regions, with weights shared across regions. How does this compare to fully-connected neural networks?** \n",
    "\n",
    "A: Each convolutional filter share the same weights across all regions. Fully-connected nets use different weights for different nodes. In vision, if we consider each pixel of a input image as a node, then a convolutional filter uses a fixed-size kernel to scan over the whole picture (with some padding and strides). The weights for this feature detector is only related to the size of its kernel, but not related to where it is scanning. This means weights are shared among all regions for this current feature detector. However, in a fully-connected neural network the number of weights depend on the number of input nodes and output nodes. So if an input image is fully-connected to another layer by each node (pixel), then the number of parameters will be huge because the size of a high-resolution photo nowadays is very large. Thus, by using convolutional filters (networks), we can reduce the number of learnable model parameters dramatically and perform much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TooSimpleConvNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 3x3 convolution that takes in an image with one channel\n",
    "        # and outputs an image with 8 channels.\n",
    "        self.conv1 = torch.nn.Conv2d(1, 8, kernel_size=3)\n",
    "        # 3x3 convolution that takes in an image with 8 channels\n",
    "        # and outputs an image with 16 channels. The output image\n",
    "        # has approximately half the height and half the width\n",
    "        # because of the stride of 2.\n",
    "        self.conv2 = torch.nn.Conv2d(8, 16, kernel_size=3, stride=2)\n",
    "        # 1x1 convolution that takes in an image with 16 channels and\n",
    "        # produces an image with 5 channels. Here, the 5 channels\n",
    "        # will correspond to class scores.\n",
    "        self.final_conv = torch.nn.Conv2d(16, 5, kernel_size=1)\n",
    "    def forward(self, x):\n",
    "        # Convolutions work with images of shape\n",
    "        # [batch_size, num_channels, height, width]\n",
    "        # reshapes our vectors back into images\n",
    "        x = x.view(-1, HEIGHT, WIDTH).unsqueeze(1) # unsqueeze(dim) -- Returns a new tensor with a dimension \n",
    "                                                   # of size one inserted at the specified position.\n",
    "                                                   # (the new dim is at 1st dim, which is the channel. Since input \n",
    "                                                   #  is absolutely 1 channel image, this new dim len should be 1)\n",
    "        # two convolutional layers\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        n, c, h, w = x.size()\n",
    "        # averages each channel spatially, so that each ‘image’ ends up with a height and width of 1\n",
    "        x = F.avg_pool2d(x, kernel_size=[h, w])\n",
    "        x = self.final_conv(x).view(-1, NUM_CLASSES)\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
